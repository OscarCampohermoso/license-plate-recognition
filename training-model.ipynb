{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7288,"status":"ok","timestamp":1728338553493,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"L2BGJzG8x6So","outputId":"638db3df-d5b0-4b01-eec1-33a126da7e06"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=1P-oVR0J35Dw40lzw47sE19oADSW-tyb1&confirm=t\n","To: /content/demo.mp4\n","100% 9.56M/9.56M [00:00<00:00, 12.2MB/s]\n"]}],"source":["!gdown \"https://drive.google.com/uc?id=1P-oVR0J35Dw40lzw47sE19oADSW-tyb1&confirm=t\""]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["folder_path = \".\""]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5288,"status":"ok","timestamp":1728499643648,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"kSlgX3o-vYh3","outputId":"685ee2c2-e224-448b-ba34-8d612a0cdda1"},"outputs":[],"source":["import cv2 as cv\n","from glob import glob\n","import os\n","import random\n","import torch\n","from ultralytics import YOLO"]},{"cell_type":"markdown","metadata":{"id":"dhr3LZCOvYh5"},"source":["# Pre-Trained YOLOv8"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1728338610856,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"rP2iMlCPvYh5","outputId":"f1378ff7-0580-4aa4-9cf9-542dc1ffba2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["['./inputs\\\\demo.mp4']\n"]}],"source":["# read in video paths\n","videos = glob(folder_path + '/inputs/*.mp4')\n","print(videos)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2024,"status":"ok","timestamp":1728338616750,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"YlJ7iRsRvYh6","outputId":"4655f599-785b-4981-9c57-d057f861c109"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 309MB/s]\n"]}],"source":["# pick pre-trained model\n","model_pretrained = YOLO('yolov8n.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49509,"status":"ok","timestamp":1728338675813,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"etnSwIQqvYh6","outputId":"8280f30f-93b9-4989-d548-7c0cc8c74e00"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lapx>=0.5.2'] not found, attempting AutoUpdate...\n","Collecting lapx>=0.5.2\n","  Downloading lapx-0.5.10.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n","Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from lapx>=0.5.2) (1.26.4)\n","Downloading lapx-0.5.10.post1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n","   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 176.7 MB/s eta 0:00:00\n","Installing collected packages: lapx\n","Successfully installed lapx-0.5.10.post1\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 2.5s, installed 1 package: ['lapx>=0.5.2']\n","\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","\n","0: 416x640 2 cars, 121.7ms\n","Speed: 16.5ms preprocess, 121.7ms inference, 1131.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.3ms\n","Speed: 3.7ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.3ms\n","Speed: 5.1ms preprocess, 12.3ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.4ms\n","Speed: 4.1ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.5ms\n","Speed: 4.3ms preprocess, 12.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.3ms\n","Speed: 4.4ms preprocess, 8.3ms inference, 3.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.0ms\n","Speed: 3.0ms preprocess, 12.0ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 16.6ms\n","Speed: 5.3ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 13.7ms\n","Speed: 3.4ms preprocess, 13.7ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.5ms\n","Speed: 3.4ms preprocess, 10.5ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.4ms\n","Speed: 5.3ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.5ms\n","Speed: 3.2ms preprocess, 9.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.9ms\n","Speed: 2.9ms preprocess, 9.9ms inference, 2.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 19.0ms\n","Speed: 3.1ms preprocess, 19.0ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.6ms\n","Speed: 3.0ms preprocess, 11.6ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.4ms\n","Speed: 4.3ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.4ms\n","Speed: 3.0ms preprocess, 12.4ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.6ms\n","Speed: 3.0ms preprocess, 10.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.2ms\n","Speed: 3.1ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.8ms\n","Speed: 3.6ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.3ms\n","Speed: 3.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.2ms\n","Speed: 3.4ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.3ms\n","Speed: 4.9ms preprocess, 9.3ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.8ms\n","Speed: 4.1ms preprocess, 11.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.9ms\n","Speed: 4.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.8ms\n","Speed: 3.2ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.0ms\n","Speed: 2.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 7.1ms\n","Speed: 3.5ms preprocess, 7.1ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 6.8ms\n","Speed: 3.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.8ms\n","Speed: 3.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.0ms\n","Speed: 3.3ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 2.9ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 7.1ms\n","Speed: 3.5ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.9ms\n","Speed: 2.0ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.7ms\n","Speed: 2.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.3ms\n","Speed: 3.3ms preprocess, 10.3ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.7ms\n","Speed: 3.4ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.8ms\n","Speed: 2.7ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.7ms\n","Speed: 4.5ms preprocess, 11.7ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.3ms\n","Speed: 3.0ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.0ms\n","Speed: 3.4ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.7ms\n","Speed: 3.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 3.0ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.7ms\n","Speed: 3.0ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.7ms\n","Speed: 3.0ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.1ms\n","Speed: 5.7ms preprocess, 10.1ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.1ms\n","Speed: 2.9ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 3.3ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 3.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 3.7ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 3.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.0ms\n","Speed: 3.4ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.4ms\n","Speed: 3.8ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.7ms\n","Speed: 3.5ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.6ms\n","Speed: 4.3ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.7ms\n","Speed: 2.9ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.6ms\n","Speed: 3.4ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.0ms\n","Speed: 3.4ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.3ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.3ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.6ms\n","Speed: 3.2ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.1ms\n","Speed: 3.0ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 13.1ms\n","Speed: 6.8ms preprocess, 13.1ms inference, 3.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.5ms\n","Speed: 2.9ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.0ms\n","Speed: 4.1ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.1ms\n","Speed: 2.7ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.0ms\n","Speed: 3.4ms preprocess, 11.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.7ms\n","Speed: 2.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.2ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.2ms\n","Speed: 2.9ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.7ms\n","Speed: 2.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.1ms\n","Speed: 3.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.9ms\n","Speed: 2.8ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.1ms\n","Speed: 3.4ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.7ms\n","Speed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.4ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 16.3ms\n","Speed: 3.3ms preprocess, 16.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.2ms\n","Speed: 5.8ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.9ms\n","Speed: 3.1ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.9ms\n","Speed: 3.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.4ms\n","Speed: 3.6ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.8ms\n","Speed: 4.0ms preprocess, 11.8ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.2ms\n","Speed: 5.2ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 suitcase, 7.3ms\n","Speed: 3.5ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 2.7ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 3.0ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.9ms\n","Speed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 suitcase, 8.4ms\n","Speed: 5.9ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.8ms\n","Speed: 2.7ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.7ms\n","Speed: 3.7ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 suitcase, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 suitcase, 7.0ms\n","Speed: 3.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 suitcase, 9.2ms\n","Speed: 3.4ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.8ms\n","Speed: 3.8ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.6ms\n","Speed: 3.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.9ms\n","Speed: 3.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.2ms\n","Speed: 3.6ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 11.5ms\n","Speed: 3.3ms preprocess, 11.5ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.9ms\n","Speed: 2.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 8.1ms\n","Speed: 3.5ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.6ms\n","Speed: 3.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.7ms\n","Speed: 3.2ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.6ms\n","Speed: 3.3ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.3ms\n","Speed: 3.5ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.9ms\n","Speed: 4.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 8.7ms\n","Speed: 9.0ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.0ms\n","Speed: 2.2ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.7ms\n","Speed: 2.4ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.0ms\n","Speed: 3.0ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.1ms\n","Speed: 2.3ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 10.3ms\n","Speed: 2.6ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.2ms\n","Speed: 5.9ms preprocess, 9.2ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 10.4ms\n","Speed: 2.8ms preprocess, 10.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.3ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.9ms\n","Speed: 3.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.8ms\n","Speed: 3.0ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.6ms\n","Speed: 3.2ms preprocess, 7.6ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.9ms\n","Speed: 3.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.0ms\n","Speed: 3.1ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.7ms\n","Speed: 2.3ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.6ms\n","Speed: 2.3ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.9ms\n","Speed: 5.3ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.6ms\n","Speed: 2.7ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.7ms\n","Speed: 3.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.3ms\n","Speed: 3.5ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.9ms\n","Speed: 5.5ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 10.5ms\n","Speed: 5.0ms preprocess, 10.5ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 12.0ms\n","Speed: 3.6ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 9.0ms\n","Speed: 3.9ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.1ms\n","Speed: 2.9ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 6.9ms\n","Speed: 3.1ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.0ms\n","Speed: 2.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.9ms\n","Speed: 3.1ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.8ms\n","Speed: 3.4ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 2.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.5ms\n","Speed: 3.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 2.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.8ms\n","Speed: 4.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.3ms\n","Speed: 2.9ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.8ms\n","Speed: 2.9ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.8ms\n","Speed: 4.6ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 9.2ms\n","Speed: 3.1ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 12.1ms\n","Speed: 3.3ms preprocess, 12.1ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 9.2ms\n","Speed: 4.2ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.4ms\n","Speed: 2.9ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.6ms\n","Speed: 3.2ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.9ms\n","Speed: 1.9ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 6.8ms\n","Speed: 2.9ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.0ms\n","Speed: 3.6ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.6ms\n","Speed: 3.0ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.9ms\n","Speed: 3.4ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.2ms\n","Speed: 3.3ms preprocess, 7.2ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.8ms\n","Speed: 3.3ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.8ms\n","Speed: 3.2ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.2ms\n","Speed: 2.6ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.9ms\n","Speed: 2.7ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 3.1ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.0ms\n","Speed: 2.8ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 6.6ms\n","Speed: 3.4ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 9.3ms\n","Speed: 3.6ms preprocess, 9.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 12.0ms\n","Speed: 3.8ms preprocess, 12.0ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.9ms\n","Speed: 3.8ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 2.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.9ms\n","Speed: 3.5ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.8ms\n","Speed: 1.9ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 6.7ms\n","Speed: 3.4ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.7ms\n","Speed: 3.5ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.5ms\n","Speed: 3.0ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.5ms\n","Speed: 3.0ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.2ms\n","Speed: 3.0ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 9.3ms\n","Speed: 1.9ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 8.9ms\n","Speed: 3.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.3ms\n","Speed: 2.9ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 6.8ms\n","Speed: 1.8ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 7.3ms\n","Speed: 2.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 10.0ms\n","Speed: 3.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 12.1ms\n","Speed: 5.8ms preprocess, 12.1ms inference, 5.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 4 cars, 12.2ms\n","Speed: 5.7ms preprocess, 12.2ms inference, 2.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 11.7ms\n","Speed: 4.2ms preprocess, 11.7ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.1ms\n","Speed: 3.2ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 10.9ms\n","Speed: 4.2ms preprocess, 10.9ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 10.7ms\n","Speed: 4.4ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 13.2ms\n","Speed: 3.1ms preprocess, 13.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.6ms\n","Speed: 4.0ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 8.6ms\n","Speed: 3.7ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.5ms\n","Speed: 3.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.5ms\n","Speed: 3.0ms preprocess, 12.5ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 14.3ms\n","Speed: 4.4ms preprocess, 14.3ms inference, 2.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.3ms\n","Speed: 3.0ms preprocess, 12.3ms inference, 5.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 2.9ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.0ms\n","Speed: 3.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 8.0ms\n","Speed: 3.0ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 8.8ms\n","Speed: 3.0ms preprocess, 8.8ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 8.4ms\n","Speed: 3.4ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 8.6ms\n","Speed: 2.8ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 9.7ms\n","Speed: 3.1ms preprocess, 9.7ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 8.9ms\n","Speed: 3.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 12.2ms\n","Speed: 6.2ms preprocess, 12.2ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 12.7ms\n","Speed: 3.3ms preprocess, 12.7ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 11.8ms\n","Speed: 3.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 7.9ms\n","Speed: 3.2ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 9.7ms\n","Speed: 3.2ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 8.6ms\n","Speed: 3.6ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 10.5ms\n","Speed: 3.0ms preprocess, 10.5ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 12.3ms\n","Speed: 3.3ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 bus, 10.3ms\n","Speed: 3.3ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 13.7ms\n","Speed: 5.3ms preprocess, 13.7ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 10.1ms\n","Speed: 6.2ms preprocess, 10.1ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 12.1ms\n","Speed: 3.1ms preprocess, 12.1ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 17.5ms\n","Speed: 4.3ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 bus, 17.8ms\n","Speed: 2.9ms preprocess, 17.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 14.1ms\n","Speed: 6.9ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 10.9ms\n","Speed: 3.1ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 1 bus, 14.0ms\n","Speed: 3.0ms preprocess, 14.0ms inference, 3.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 1 truck, 14.8ms\n","Speed: 3.1ms preprocess, 14.8ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 1 truck, 14.5ms\n","Speed: 3.1ms preprocess, 14.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 1 bus, 10.3ms\n","Speed: 6.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 bus, 9.6ms\n","Speed: 5.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 bus, 9.4ms\n","Speed: 3.0ms preprocess, 9.4ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 10.0ms\n","Speed: 3.7ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 11.4ms\n","Speed: 3.0ms preprocess, 11.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 13.0ms\n","Speed: 3.5ms preprocess, 13.0ms inference, 2.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 16.5ms\n","Speed: 3.1ms preprocess, 16.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 8.9ms\n","Speed: 2.9ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 8.9ms\n","Speed: 3.3ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 9.3ms\n","Speed: 3.1ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 15.4ms\n","Speed: 3.0ms preprocess, 15.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 9.4ms\n","Speed: 2.9ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 13.1ms\n","Speed: 3.1ms preprocess, 13.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 19.2ms\n","Speed: 3.0ms preprocess, 19.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.2ms\n","Speed: 3.0ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 motorcycle, 8.9ms\n","Speed: 3.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 motorcycle, 11.8ms\n","Speed: 3.2ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 motorcycle, 11.4ms\n","Speed: 3.2ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.5ms\n","Speed: 5.5ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 14.0ms\n","Speed: 3.1ms preprocess, 14.0ms inference, 3.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 9.7ms\n","Speed: 2.9ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 11.9ms\n","Speed: 2.9ms preprocess, 11.9ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 3 cars, 13.5ms\n","Speed: 4.4ms preprocess, 13.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 3 cars, 12.8ms\n","Speed: 3.2ms preprocess, 12.8ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 12.6ms\n","Speed: 2.9ms preprocess, 12.6ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 14.1ms\n","Speed: 3.1ms preprocess, 14.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 15.1ms\n","Speed: 5.5ms preprocess, 15.1ms inference, 3.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 1 truck, 10.3ms\n","Speed: 3.1ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 10.1ms\n","Speed: 2.9ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 2 cars, 1 truck, 14.4ms\n","Speed: 3.1ms preprocess, 14.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 7.8ms\n","Speed: 3.5ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 8.8ms\n","Speed: 3.1ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 3 cars, 9.2ms\n","Speed: 3.2ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 10.9ms\n","Speed: 3.2ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 persons, 1 car, 1 truck, 14.7ms\n","Speed: 3.2ms preprocess, 14.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 persons, 5 cars, 2 trucks, 11.8ms\n","Speed: 3.3ms preprocess, 11.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.7ms\n","Speed: 3.0ms preprocess, 9.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.5ms\n","Speed: 3.2ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 13.5ms\n","Speed: 3.1ms preprocess, 13.5ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.3ms\n","Speed: 3.7ms preprocess, 11.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 18.2ms\n","Speed: 3.1ms preprocess, 18.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 17.2ms\n","Speed: 5.7ms preprocess, 17.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 9.6ms\n","Speed: 3.1ms preprocess, 9.6ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.7ms\n","Speed: 5.1ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 12.5ms\n","Speed: 5.3ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 10.5ms\n","Speed: 3.1ms preprocess, 10.5ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 2 trucks, 10.7ms\n","Speed: 3.2ms preprocess, 10.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 2 trucks, 10.8ms\n","Speed: 3.2ms preprocess, 10.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 11.4ms\n","Speed: 4.0ms preprocess, 11.4ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 12.3ms\n","Speed: 4.2ms preprocess, 12.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 11.6ms\n","Speed: 3.2ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 11.6ms\n","Speed: 7.2ms preprocess, 11.6ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 10.9ms\n","Speed: 3.5ms preprocess, 10.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 2 trucks, 9.7ms\n","Speed: 3.5ms preprocess, 9.7ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.4ms\n","Speed: 3.4ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.2ms\n","Speed: 2.9ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 2 trucks, 6.9ms\n","Speed: 3.2ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 2 trucks, 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.8ms\n","Speed: 3.1ms preprocess, 8.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.6ms\n","Speed: 3.2ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.8ms\n","Speed: 3.1ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 8.3ms\n","Speed: 3.0ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.6ms\n","Speed: 2.0ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.4ms\n","Speed: 3.5ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.6ms\n","Speed: 3.3ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 9.8ms\n","Speed: 2.2ms preprocess, 9.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 2.6ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.5ms\n","Speed: 3.4ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 4.2ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 7.1ms\n","Speed: 3.4ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 12.7ms\n","Speed: 5.8ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 11.5ms\n","Speed: 2.1ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 2 trucks, 9.6ms\n","Speed: 7.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 9.7ms\n","Speed: 3.1ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 6.9ms\n","Speed: 2.6ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.1ms\n","Speed: 2.9ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 4.8ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 8.3ms\n","Speed: 2.9ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 9.0ms\n","Speed: 4.5ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 7.7ms\n","Speed: 3.2ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 10.7ms\n","Speed: 3.2ms preprocess, 10.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 6.6ms\n","Speed: 2.9ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 7.1ms\n","Speed: 3.1ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 7.2ms\n","Speed: 3.2ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 7.8ms\n","Speed: 3.4ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 7.8ms\n","Speed: 3.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 7.8ms\n","Speed: 3.2ms preprocess, 7.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 13.8ms\n","Speed: 5.8ms preprocess, 13.8ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 11.4ms\n","Speed: 3.0ms preprocess, 11.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 11.4ms\n","Speed: 6.2ms preprocess, 11.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 8.7ms\n","Speed: 2.9ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.0ms\n","Speed: 3.0ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.4ms\n","Speed: 2.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.9ms\n","Speed: 2.8ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.6ms\n","Speed: 3.5ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 7.9ms\n","Speed: 3.1ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.9ms\n","Speed: 2.9ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.1ms\n","Speed: 3.5ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 8.3ms\n","Speed: 4.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.3ms\n","Speed: 4.6ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.8ms\n","Speed: 2.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 10.4ms\n","Speed: 3.6ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.8ms\n","Speed: 4.7ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.2ms\n","Speed: 2.7ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 10.1ms\n","Speed: 5.7ms preprocess, 10.1ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 7.8ms\n","Speed: 3.1ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.4ms\n","Speed: 3.3ms preprocess, 8.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 7.7ms\n","Speed: 3.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 bus, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.9ms\n","Speed: 3.0ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 6.6ms\n","Speed: 2.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.1ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.3ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.3ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 6.7ms\n","Speed: 2.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 8.0ms\n","Speed: 3.7ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 7.0ms\n","Speed: 3.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 3 cars, 7.6ms\n","Speed: 3.3ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 1 truck, 9.1ms\n","Speed: 5.5ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 10.9ms\n","Speed: 3.1ms preprocess, 10.9ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 11.9ms\n","Speed: 3.9ms preprocess, 11.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 12.3ms\n","Speed: 2.1ms preprocess, 12.3ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 12.8ms\n","Speed: 3.3ms preprocess, 12.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 2 cars, 10.5ms\n","Speed: 2.4ms preprocess, 10.5ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 9.1ms\n","Speed: 3.0ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 person, 1 car, 1 truck, 8.4ms\n","Speed: 2.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 1 parking meter, 7.0ms\n","Speed: 3.5ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 parking meter, 6.7ms\n","Speed: 3.0ms preprocess, 6.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 parking meter, 7.4ms\n","Speed: 3.3ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.8ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.6ms\n","Speed: 2.5ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.6ms\n","Speed: 2.3ms preprocess, 6.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 3.4ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.9ms\n","Speed: 3.1ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 6.8ms\n","Speed: 2.6ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 10.3ms\n","Speed: 4.2ms preprocess, 10.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 8.9ms\n","Speed: 2.5ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 truck, 9.0ms\n","Speed: 5.1ms preprocess, 9.0ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.6ms\n","Speed: 6.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.7ms\n","Speed: 2.9ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.5ms\n","Speed: 3.1ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.8ms\n","Speed: 3.1ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.4ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 3.4ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.6ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.9ms\n","Speed: 3.6ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 3.2ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.2ms\n","Speed: 5.7ms preprocess, 10.2ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.8ms\n","Speed: 3.3ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.6ms\n","Speed: 3.5ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.0ms\n","Speed: 9.2ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.5ms\n","Speed: 2.8ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.0ms\n","Speed: 3.6ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.6ms\n","Speed: 3.4ms preprocess, 10.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.1ms\n","Speed: 5.0ms preprocess, 9.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.7ms\n","Speed: 4.5ms preprocess, 11.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 14.2ms\n","Speed: 7.2ms preprocess, 14.2ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.7ms\n","Speed: 3.3ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.1ms\n","Speed: 3.6ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.4ms\n","Speed: 3.2ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.1ms\n","Speed: 3.2ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.6ms\n","Speed: 2.1ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.8ms\n","Speed: 4.7ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.9ms\n","Speed: 2.5ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.9ms\n","Speed: 2.9ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.0ms\n","Speed: 2.9ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 3.2ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.9ms\n","Speed: 3.1ms preprocess, 7.9ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.4ms\n","Speed: 2.6ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.4ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 3.6ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.8ms\n","Speed: 2.8ms preprocess, 8.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.7ms\n","Speed: 3.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.4ms\n","Speed: 4.5ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.5ms\n","Speed: 2.9ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.3ms\n","Speed: 3.4ms preprocess, 10.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.1ms\n","Speed: 3.0ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.6ms\n","Speed: 3.9ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.1ms\n","Speed: 2.9ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 3.4ms preprocess, 7.8ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.6ms\n","Speed: 3.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.4ms\n","Speed: 3.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.2ms\n","Speed: 3.1ms preprocess, 8.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.1ms\n","Speed: 3.7ms preprocess, 7.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 3.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 airplane, 19.5ms\n","Speed: 3.2ms preprocess, 19.5ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.7ms\n","Speed: 3.1ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.6ms\n","Speed: 3.6ms preprocess, 8.6ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.2ms\n","Speed: 3.1ms preprocess, 12.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 keyboard, 11.2ms\n","Speed: 3.0ms preprocess, 11.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.4ms\n","Speed: 3.0ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.5ms\n","Speed: 5.2ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.5ms\n","Speed: 3.0ms preprocess, 11.5ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.3ms\n","Speed: 3.5ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.0ms\n","Speed: 3.0ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.5ms\n","Speed: 3.3ms preprocess, 9.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.2ms\n","Speed: 3.7ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.7ms\n","Speed: 7.4ms preprocess, 8.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.7ms\n","Speed: 4.3ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.1ms\n","Speed: 3.3ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.7ms\n","Speed: 3.1ms preprocess, 11.7ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.0ms\n","Speed: 5.0ms preprocess, 11.0ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 13.7ms\n","Speed: 3.3ms preprocess, 13.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 14.5ms\n","Speed: 3.4ms preprocess, 14.5ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.6ms\n","Speed: 3.2ms preprocess, 10.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.2ms\n","Speed: 3.3ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.1ms\n","Speed: 5.4ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.0ms\n","Speed: 3.2ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.3ms\n","Speed: 3.1ms preprocess, 10.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.2ms\n","Speed: 3.0ms preprocess, 10.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.1ms\n","Speed: 4.6ms preprocess, 9.1ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.5ms\n","Speed: 3.1ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.8ms\n","Speed: 3.4ms preprocess, 12.8ms inference, 2.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.5ms\n","Speed: 3.1ms preprocess, 10.5ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.7ms\n","Speed: 3.1ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 13.9ms\n","Speed: 2.9ms preprocess, 13.9ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 13.4ms\n","Speed: 3.5ms preprocess, 13.4ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.2ms\n","Speed: 3.3ms preprocess, 10.2ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.8ms\n","Speed: 3.5ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.4ms\n","Speed: 5.4ms preprocess, 11.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.2ms\n","Speed: 6.1ms preprocess, 12.2ms inference, 3.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.1ms\n","Speed: 6.2ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.3ms\n","Speed: 4.3ms preprocess, 9.3ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.2ms\n","Speed: 5.1ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 15.2ms\n","Speed: 4.6ms preprocess, 15.2ms inference, 2.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 17.5ms\n","Speed: 3.3ms preprocess, 17.5ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.9ms\n","Speed: 4.3ms preprocess, 11.9ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 12.8ms\n","Speed: 3.2ms preprocess, 12.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 9.4ms\n","Speed: 3.7ms preprocess, 9.4ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 10.6ms\n","Speed: 3.0ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 9.8ms\n","Speed: 3.3ms preprocess, 9.8ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 9.4ms\n","Speed: 3.6ms preprocess, 9.4ms inference, 3.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 11.2ms\n","Speed: 3.4ms preprocess, 11.2ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 11.6ms\n","Speed: 3.1ms preprocess, 11.6ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 15.3ms\n","Speed: 3.5ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 6.9ms\n","Speed: 2.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 trucks, 11.2ms\n","Speed: 3.4ms preprocess, 11.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.9ms\n","Speed: 4.1ms preprocess, 8.9ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.8ms\n","Speed: 3.0ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.9ms\n","Speed: 3.1ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.4ms\n","Speed: 3.2ms preprocess, 8.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.2ms\n","Speed: 3.2ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.6ms\n","Speed: 3.0ms preprocess, 8.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.4ms\n","Speed: 3.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.5ms\n","Speed: 3.3ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.6ms\n","Speed: 2.9ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.6ms\n","Speed: 3.1ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.0ms\n","Speed: 3.2ms preprocess, 7.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.6ms\n","Speed: 3.8ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 11.1ms\n","Speed: 3.1ms preprocess, 11.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.4ms\n","Speed: 2.9ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 7.7ms\n","Speed: 3.0ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 8.3ms\n","Speed: 3.0ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 1 truck, 11.1ms\n","Speed: 3.1ms preprocess, 11.1ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 10.5ms\n","Speed: 2.6ms preprocess, 10.5ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.9ms\n","Speed: 4.1ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 9.3ms\n","Speed: 3.7ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 8.4ms\n","Speed: 6.1ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 1 truck, 8.2ms\n","Speed: 3.1ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.5ms\n","Speed: 2.9ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.0ms\n","Speed: 2.9ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.7ms\n","Speed: 3.0ms preprocess, 7.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 10.8ms\n","Speed: 4.5ms preprocess, 10.8ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.6ms\n","Speed: 3.1ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.2ms\n","Speed: 3.8ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.5ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.9ms\n","Speed: 3.5ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.3ms\n","Speed: 3.5ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 3.0ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.0ms\n","Speed: 4.6ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.2ms\n","Speed: 3.5ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.4ms\n","Speed: 2.3ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.3ms\n","Speed: 3.0ms preprocess, 10.3ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.2ms\n","Speed: 5.5ms preprocess, 9.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.1ms\n","Speed: 2.9ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.7ms\n","Speed: 3.6ms preprocess, 10.7ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.3ms\n","Speed: 6.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.7ms\n","Speed: 5.1ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.6ms\n","Speed: 3.4ms preprocess, 6.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.8ms\n","Speed: 3.5ms preprocess, 6.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.3ms\n","Speed: 3.5ms preprocess, 7.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.2ms\n","Speed: 4.4ms preprocess, 7.2ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.6ms\n","Speed: 3.1ms preprocess, 7.6ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.8ms\n","Speed: 3.0ms preprocess, 7.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.1ms\n","Speed: 3.9ms preprocess, 10.1ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.4ms\n","Speed: 3.0ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.1ms\n","Speed: 3.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.9ms\n","Speed: 3.3ms preprocess, 7.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.5ms\n","Speed: 3.0ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.9ms\n","Speed: 3.0ms preprocess, 10.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.9ms\n","Speed: 5.1ms preprocess, 8.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.8ms\n","Speed: 2.6ms preprocess, 11.8ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.6ms\n","Speed: 3.0ms preprocess, 11.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.1ms\n","Speed: 3.2ms preprocess, 8.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.0ms\n","Speed: 2.8ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.0ms\n","Speed: 3.0ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.6ms\n","Speed: 3.2ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.6ms\n","Speed: 3.0ms preprocess, 11.6ms inference, 1.8ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.5ms\n","Speed: 3.8ms preprocess, 7.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.5ms\n","Speed: 3.1ms preprocess, 9.5ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.0ms\n","Speed: 3.5ms preprocess, 7.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.0ms\n","Speed: 3.2ms preprocess, 10.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.5ms\n","Speed: 4.2ms preprocess, 12.5ms inference, 1.9ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.7ms\n","Speed: 3.1ms preprocess, 7.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.8ms\n","Speed: 3.5ms preprocess, 6.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.9ms\n","Speed: 4.0ms preprocess, 9.9ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 12.1ms\n","Speed: 3.1ms preprocess, 12.1ms inference, 2.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.0ms\n","Speed: 3.3ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.0ms\n","Speed: 3.2ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.7ms\n","Speed: 3.6ms preprocess, 8.7ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.6ms\n","Speed: 3.1ms preprocess, 7.6ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 6.9ms\n","Speed: 4.6ms preprocess, 6.9ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.6ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.8ms\n","Speed: 3.5ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.4ms\n","Speed: 3.2ms preprocess, 9.4ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.0ms\n","Speed: 3.3ms preprocess, 11.0ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.1ms\n","Speed: 3.1ms preprocess, 9.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 4.3ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.4ms\n","Speed: 3.0ms preprocess, 7.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.3ms\n","Speed: 3.0ms preprocess, 7.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.9ms\n","Speed: 3.2ms preprocess, 9.9ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 13.4ms\n","Speed: 5.2ms preprocess, 13.4ms inference, 3.0ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.9ms\n","Speed: 3.2ms preprocess, 8.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.5ms\n","Speed: 3.7ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.8ms\n","Speed: 3.2ms preprocess, 7.8ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.6ms\n","Speed: 3.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 2.0ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.5ms\n","Speed: 3.6ms preprocess, 7.5ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.7ms\n","Speed: 3.6ms preprocess, 9.7ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.3ms\n","Speed: 3.1ms preprocess, 8.3ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.9ms\n","Speed: 2.5ms preprocess, 6.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.8ms\n","Speed: 3.3ms preprocess, 8.8ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.2ms\n","Speed: 3.5ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.5ms\n","Speed: 3.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.2ms\n","Speed: 3.4ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.3ms\n","Speed: 4.2ms preprocess, 10.3ms inference, 1.7ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 10.2ms\n","Speed: 4.7ms preprocess, 10.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.2ms\n","Speed: 5.9ms preprocess, 9.2ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.5ms\n","Speed: 3.4ms preprocess, 8.5ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.2ms\n","Speed: 3.0ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 9.0ms\n","Speed: 4.6ms preprocess, 9.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 6.7ms\n","Speed: 2.0ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.2ms\n","Speed: 3.1ms preprocess, 7.2ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.2ms\n","Speed: 3.3ms preprocess, 8.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.1ms\n","Speed: 3.2ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.0ms\n","Speed: 3.1ms preprocess, 8.0ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.0ms\n","Speed: 4.2ms preprocess, 8.0ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 11.9ms\n","Speed: 3.2ms preprocess, 11.9ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 7.4ms\n","Speed: 3.8ms preprocess, 7.4ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 1 car, 8.8ms\n","Speed: 4.3ms preprocess, 8.8ms inference, 1.3ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.1ms\n","Speed: 3.0ms preprocess, 8.1ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.2ms\n","Speed: 2.8ms preprocess, 7.2ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.7ms\n","Speed: 3.0ms preprocess, 8.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 9.6ms\n","Speed: 4.1ms preprocess, 9.6ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.2ms\n","Speed: 3.0ms preprocess, 11.2ms inference, 1.5ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 11.7ms\n","Speed: 3.6ms preprocess, 11.7ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 12.2ms\n","Speed: 3.4ms preprocess, 12.2ms inference, 1.6ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 8.4ms\n","Speed: 4.5ms preprocess, 8.4ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 2 cars, 7.1ms\n","Speed: 2.0ms preprocess, 7.1ms inference, 1.2ms postprocess per image at shape (1, 3, 416, 640)\n","\n","0: 416x640 3 cars, 1 truck, 6.7ms\n","Speed: 2.9ms preprocess, 6.7ms inference, 1.1ms postprocess per image at shape (1, 3, 416, 640)\n","Video saved at: /content/drive/My Drive/YOLOv8 License Plate Detection/outputs/demo.mp4\n"]}],"source":["# read video by index\n","video = cv.VideoCapture(videos[0])\n","\n","# get video dimensions\n","frame_width = int(video.get(3))\n","frame_height = int(video.get(4))\n","size = (frame_width, frame_height)\n","\n","# Define the codec and create VideoWriter object for MP4\n","fourcc = cv.VideoWriter_fourcc(*'mp4v')  # MP4 codec\n","output_path = os.path.join(folder_path, 'outputs', 'demo.mp4')\n","out = cv.VideoWriter(output_path, fourcc, 20.0, size)\n","\n","ret = True\n","while ret:\n","    ret, frame = video.read()\n","\n","    if ret:\n","        results = model_pretrained.track(frame, persist=True)\n","        composed = results[0].plot()\n","\n","        # save video\n","        out.write(composed)\n","\n","# Release everything once job is finished\n","out.release()\n","video.release()\n","\n","print(f\"Video saved at: {output_path}\")"]},{"cell_type":"markdown","metadata":{"id":"cGpa6JwsvYh6"},"source":["# Retraining YOLOv8"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import os\n","os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":492,"status":"ok","timestamp":1728499655744,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"uXXS7YUeHIMu","outputId":"0d25f001-c2cf-4f62-bce1-19a78dd58f0e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1346,"status":"ok","timestamp":1728499661246,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"FOsEkRaVvYh7","outputId":"c1b0b16a-7bac-44bd-ecbe-68220f1e44e0"},"outputs":[],"source":["dataset = folder_path+ '/data.yaml'\n","\n","# load a model\n","# backbone = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n","backbone = YOLO(\"yolov8n.pt\")  # load a pre-trained model (recommended for training)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2109611,"status":"error","timestamp":1728501774304,"user":{"displayName":"Oscar Campohermoso Berdeja","userId":"10914934622322665476"},"user_tz":240},"id":"ad2HEbc5vYh7","outputId":"47c7bc8f-8c3e-4479-b22a-c88501055e72"},"outputs":[{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.9  Python-3.10.13 torch-2.4.1+cpu CPU (Intel Core(TM) i5-8400 2.80GHz)\n","\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=./data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","Model summary: 249 layers, 2,690,403 parameters, 2,690,387 gradients, 6.9 GFLOPs\n","\n","Transferred 313/391 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train3', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\development\\computer-vision\\license-plate-imgs\\train\\labels.cache... 21173 images, 28 backgrounds, 0 corrupt: 100%|██████████| 21173/21173 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\development\\computer-vision\\license-plate-imgs\\valid\\labels.cache... 2046 images, 3 backgrounds, 0 corrupt: 100%|██████████| 2046/2046 [00:00<?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs\\detect\\train3\\labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/20         0G      1.494      3.813      1.495         24        640:   6%|▌         | 79/1324 [07:32<1:58:48,  5.73s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mbackbone\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ocamp\\.conda\\envs\\classification\\lib\\site-packages\\ultralytics\\engine\\model.py:802\u001b[0m, in \u001b[0;36mModel.train\u001b[1;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m    801\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[1;32m--> 802\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n","File \u001b[1;32mc:\\Users\\ocamp\\.conda\\envs\\classification\\lib\\site-packages\\ultralytics\\engine\\trainer.py:207\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ocamp\\.conda\\envs\\classification\\lib\\site-packages\\ultralytics\\engine\\trainer.py:393\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[1;34m(self, world_size)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    389\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;241m*\u001b[39m i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items) \u001b[38;5;241m/\u001b[39m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_items\n\u001b[0;32m    390\u001b[0m     )\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Backward\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ni \u001b[38;5;241m-\u001b[39m last_opt_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccumulate:\n","File \u001b[1;32mc:\\Users\\ocamp\\.conda\\envs\\classification\\lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ocamp\\.conda\\envs\\classification\\lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\ocamp\\.conda\\envs\\classification\\lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    770\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    771\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Use the model\n","results = backbone.train(data=dataset, epochs=20, device=device)  # train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USYWt0XcmVeW"},"outputs":[],"source":["model_save_path = folder_path + '/runs/trained_yolov8n.pt'  # Save in your drive folder\n","backbone.model.save(model_save_path)  # Manually save the trained model\n","\n","print(f\"Model saved to {model_save_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fMW6bT6NvYh7"},"outputs":[],"source":["# Evaluate the model's performance on the validation set\n","results = backbone.val()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h2zRapo5vYh8"},"outputs":[],"source":["# Perform object detection on an image using the model\n","results = backbone('inputs/car.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eZf1xHGCvYh8"},"outputs":[],"source":["# Export the model to ONNX format\n","# success = model.export(imgsz=(640, 480), format='onnx', opset=12, optimize=False, half=False)\n","# Export to PyTorch format\n","success = backbone.export(imgsz=640, format='torchscript', optimize=False, half=False, int8=False)\n","# TorchScript: export success ✅ 1.5s, saved as 'runs/detect/train11/weights/best.torchscript' (11.9 MB)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xouTelVvYh8"},"outputs":[],"source":["# pick pre-trained model\n","np_model = YOLO('runs/detect/train11/weights/best.torchscript')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GEhAdP5NvYh8"},"outputs":[],"source":["# read video by index\n","video = cv.VideoCapture(videos[0])\n","\n","# get video dimensions\n","frame_width = int(video.get(3))\n","frame_height = int(video.get(4))\n","size = (frame_width, frame_height)\n","\n","# Define the codec and create VideoWriter object for MP4\n","fourcc = cv.VideoWriter_fourcc(*'mp4v')  # MP4 codec\n","output_path = os.path.join(folder_path, 'outputs', 'demo-2.mp4')\n","out = cv.VideoWriter(output_path, fourcc, 20.0, size)\n","\n","ret = True\n","while ret:\n","    ret, frame = video.read()\n","\n","    if ret:\n","        results = model_pretrained.track(frame, persist=True)\n","        composed = results[0].plot()\n","\n","        # save video\n","        out.write(composed)\n","\n","# Release everything once job is finished\n","out.release()\n","video.release()\n","\n","print(f\"Video saved at: {output_path}\")"]},{"cell_type":"markdown","metadata":{"id":"xjV5rFAjvYh8"},"source":["# Improving Training Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cEjrTFqUvYh9"},"outputs":[],"source":["# unzip downloaded dataset to `./datasets`\n","dataset = 'datasets/data.yaml'\n","\n","# load a model\n","# backbone = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n","backbone_small = YOLO(\"yolov8s.pt\")  # load a pre-trained model (recommended for training)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xgDGgsJ_vYh9"},"outputs":[],"source":["# Use the model\n","results_medium = backbone_small.train(data=dataset, epochs=100)  # train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ITxw37xtvYh9"},"outputs":[],"source":["# pick pre-trained model\n","np2_model = YOLO('runs/detect/train4/weights/best.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BUfH-Jt0vYh9"},"outputs":[],"source":["# Evaluate the model's performance on the validation set\n","results = np2_model.val()"]},{"cell_type":"markdown","metadata":{"id":"lI-wZv0MvYh9"},"source":["# License Plate Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za-aIAnAvYh9"},"outputs":[],"source":["import ast\n","import cv2 as cv\n","import easyocr\n","from glob import glob\n","import numpy as np\n","import pandas as pd\n","import string\n","from ultralytics import YOLO"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4a8BvjfbvYh9"},"outputs":[],"source":["# regular pre-trained yolov8 model for car recognition\n","# coco_model = YOLO('yolov8n.pt')\n","coco_model = YOLO('yolov8s.pt')\n","# yolov8 model trained to detect number plates\n","np_model = YOLO('runs/detect/train4/weights/best.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SHiIxPtvYh9"},"outputs":[],"source":["# read in test video paths\n","videos = glob('inputs/*.mp4')\n","print(videos)"]},{"cell_type":"markdown","metadata":{"id":"CJsrYlDGvYh9"},"source":["# STEP 1 Implementing the Car Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QU6-cT5xvYh9"},"outputs":[],"source":["# read video by index\n","video = cv.VideoCapture(videos[1])\n","\n","ret = True\n","frame_number = -1\n","# all vehicle class IDs from the COCO dataset (car, motorbike, truck) https://docs.ultralytics.com/datasets/detect/coco/#dataset-yaml\n","vehicles = [2,3,5]\n","vehicle_bounding_boxes = []\n","\n","# read the 10 first frames\n","while ret:\n","    frame_number += 1\n","    ret, frame = video.read()\n","\n","    if ret and frame_number < 10:\n","        # use track() to identify instances and track them frame by frame\n","        detections = coco_model.track(frame, persist=True)[0]\n","        # save cropped detections\n","        # detections.save_crop('outputs')\n","        # print nodel predictions for debugging\n","        # print(results)\n","\n","        for detection in detections.boxes.data.tolist():\n","            # print detection bounding boxes for debugging\n","            # print(detection)\n","            x1, y1, x2, y2, track_id, score, class_id = detection\n","            # I am only interested in class IDs that belong to vehicles\n","            if int(class_id) in vehicles and score > 0.5:\n","                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n","\n","# print found bounding boxes for debugging\n","print(vehicle_bounding_boxes)\n","video.release()"]},{"cell_type":"markdown","metadata":{"id":"JpoFcVmMvYh9"},"source":["# STEP 2 Implementing the License Plate Detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Isup2hk-vYh9"},"outputs":[],"source":["# read video by index\n","video = cv.VideoCapture(videos[0])\n","\n","ret = True\n","frame_number = -1\n","vehicles = [2,3,5]\n","\n","# read the 10 first frames\n","while ret:\n","    frame_number += 1\n","    ret, frame = video.read()\n","\n","    if ret and frame_number < 10:\n","\n","        # vehicle detector\n","        detections = coco_model.track(frame, persist=True)[0]\n","        for detection in detections.boxes.data.tolist():\n","            x1, y1, x2, y2, track_id, score, class_id = detection\n","            if int(class_id) in vehicles and score > 0.5:\n","                vehicle_bounding_boxes = []\n","                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n","                for bbox in vehicle_bounding_boxes:\n","                    print(bbox)\n","                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n","                    # debugging check if bbox lines up with detected vehicles (should be identical to save_crops() above\n","                    # cv.imwrite(str(track_id) + '.jpg', roi)\n","\n","                    # license plate detector for region of interest\n","                    license_plates = np_model(roi)[0]\n","                    # check every bounding box for a license plate\n","                    for license_plate in license_plates.boxes.data.tolist():\n","                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n","                        # verify detections\n","                        print(license_plate, 'track_id: ' + str(bbox[4]))\n","                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n","                        cv.imwrite(str(track_id) + '.jpg', plate)\n","\n","video.release()"]},{"cell_type":"markdown","metadata":{"id":"R2LhucNPvYh-"},"source":["# STEP 3 Preprocess License Plates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HLsGHFxNvYh-"},"outputs":[],"source":["# read video by index\n","video = cv.VideoCapture(videos[0])\n","\n","ret = True\n","frame_number = -1\n","vehicles = [2,3,5]\n","\n","# read the 10 first frames\n","while ret:\n","    frame_number += 1\n","    ret, frame = video.read()\n","\n","    if ret and frame_number < 100:\n","\n","        # vehicle detector\n","        detections = coco_model.track(frame, persist=True)[0]\n","        for detection in detections.boxes.data.tolist():\n","            x1, y1, x2, y2, track_id, score, class_id = detection\n","            if int(class_id) in vehicles and score > 0.5:\n","                vehicle_bounding_boxes = []\n","                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n","                for bbox in vehicle_bounding_boxes:\n","                    print(bbox)\n","                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n","\n","                    # license plate detector for region of interest\n","                    license_plates = np_model(roi)[0]\n","                    # process license plate\n","                    for license_plate in license_plates.boxes.data.tolist():\n","                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n","                        # crop plate from region of interest\n","                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n","                        # de-colorize\n","                        plate_gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n","                        # posterize\n","                        _, plate_treshold = cv.threshold(plate_gray, 64, 255, cv.THRESH_BINARY_INV)\n","                        cv.imwrite(str(track_id) + '_gray.jpg', plate_gray)\n","                        cv.imwrite(str(track_id) + '_thresh.jpg', plate_treshold)\n","\n","video.release()"]},{"cell_type":"markdown","metadata":{"id":"T5b-ewshvYh-"},"source":["# STEP 4 Read License Plates"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SOyakDLvYh-"},"outputs":[],"source":["# Initialize the OCR reader\n","reader = easyocr.Reader(['en'], gpu=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQf_c9UfvYh-"},"outputs":[],"source":["def read_license_plate(license_plate_crop):\n","    detections = reader.readtext(license_plate_crop)\n","\n","    for detection in detections:\n","        bbox, text, score = detection\n","\n","        text = text.upper().replace(' ', '')\n","\n","        return text, score\n","\n","    return None, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_FfaoAIvYh-"},"outputs":[],"source":["def write_csv(results, output_path):\n","\n","    with open(output_path, 'w') as f:\n","        f.write('{},{},{},{},{},{},{},{}\\n'.format(\n","            'frame_number', 'track_id', 'car_bbox', 'car_bbox_score',\n","            'license_plate_bbox', 'license_plate_bbox_score', 'license_plate_number',\n","            'license_text_score'))\n","\n","        for frame_number in results.keys():\n","            for track_id in results[frame_number].keys():\n","                print(results[frame_number][track_id])\n","                if 'car' in results[frame_number][track_id].keys() and \\\n","                   'license_plate' in results[frame_number][track_id].keys() and \\\n","                   'number' in results[frame_number][track_id]['license_plate'].keys():\n","                    f.write('{},{},{},{},{},{},{},{}\\n'.format(\n","                        frame_number,\n","                        track_id,\n","                        '[{} {} {} {}]'.format(\n","                            results[frame_number][track_id]['car']['bbox'][0],\n","                            results[frame_number][track_id]['car']['bbox'][1],\n","                            results[frame_number][track_id]['car']['bbox'][2],\n","                            results[frame_number][track_id]['car']['bbox'][3]\n","                        ),\n","                        results[frame_number][track_id]['car']['bbox_score'],\n","                        '[{} {} {} {}]'.format(\n","                            results[frame_number][track_id]['license_plate']['bbox'][0],\n","                            results[frame_number][track_id]['license_plate']['bbox'][1],\n","                            results[frame_number][track_id]['license_plate']['bbox'][2],\n","                            results[frame_number][track_id]['license_plate']['bbox'][3]\n","                        ),\n","                        results[frame_number][track_id]['license_plate']['bbox_score'],\n","                        results[frame_number][track_id]['license_plate']['number'],\n","                        results[frame_number][track_id]['license_plate']['text_score'])\n","                    )\n","        f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2yoRLSuevYh-"},"outputs":[],"source":["results = {}\n","\n","# read video by index\n","video = cv.VideoCapture(videos[0])\n","\n","ret = True\n","frame_number = -1\n","vehicles = [2,3,5]\n","\n","# read the 10 first frames\n","while ret:\n","    frame_number += 1\n","    ret, frame = video.read()\n","\n","    if ret and frame_number < 100:\n","        results[frame_number] = {}\n","\n","        # vehicle detector\n","        detections = coco_model.track(frame, persist=True)[0]\n","        for detection in detections.boxes.data.tolist():\n","            x1, y1, x2, y2, track_id, score, class_id = detection\n","            if int(class_id) in vehicles and score > 0.5:\n","                vehicle_bounding_boxes = []\n","                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n","                for bbox in vehicle_bounding_boxes:\n","                    print(bbox)\n","                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n","\n","                    # license plate detector for region of interest\n","                    license_plates = np_model(roi)[0]\n","                    # process license plate\n","                    for license_plate in license_plates.boxes.data.tolist():\n","                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n","                        # crop plate from region of interest\n","                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n","                        # de-colorize\n","                        plate_gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n","                        # posterize\n","                        _, plate_treshold = cv.threshold(plate_gray, 64, 255, cv.THRESH_BINARY_INV)\n","\n","                        # OCR\n","                        np_text, np_score = read_license_plate(plate_treshold)\n","                        # if plate could be read write results\n","                        if np_text is not None:\n","                            results[frame_number][track_id] = {\n","                                'car': {\n","                                    'bbox': [x1, y1, x2, y2],\n","                                    'bbox_score': score\n","                                },\n","                                'license_plate': {\n","                                    'bbox': [plate_x1, plate_y1, plate_x2, plate_y2],\n","                                    'bbox_score': plate_score,\n","                                    'number': np_text,\n","                                    'text_score': np_score\n","                                }\n","                            }\n","\n","write_csv(results, './results.csv')\n","video.release()"]},{"cell_type":"markdown","metadata":{"id":"A7jBpBmWvYh-"},"source":["# STEP 5 Clean-Up License Plate Format"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WPTcJRFJvYh_"},"outputs":[],"source":["# Mapping dictionaries for character conversion\n","# characters that can easily be confused can be\n","# verified by their location - an `O` in a place\n","# where a number is expected is probably a `0`\n","dict_char_to_int = {'O': '0',\n","                    'I': '1',\n","                    'J': '3',\n","                    'A': '4',\n","                    'G': '6',\n","                    'S': '5'}\n","\n","dict_int_to_char = {'0': 'O',\n","                    '1': 'I',\n","                    '3': 'J',\n","                    '4': 'A',\n","                    '6': 'G',\n","                    '5': 'S'}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mQA8C-2zvYh_"},"outputs":[],"source":["def license_complies_format(text):\n","    # True if the license plate complies with the format, False otherwise.\n","    if len(text) != 7:\n","        return False\n","\n","    if (text[0] in string.ascii_uppercase or text[0] in dict_int_to_char.keys()) and \\\n","       (text[1] in string.ascii_uppercase or text[1] in dict_int_to_char.keys()) and \\\n","       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n","       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n","       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n","       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n","       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n","        return True\n","    else:\n","        return False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D0fvk7JqvYh_"},"outputs":[],"source":["def format_license(text):\n","    license_plate_ = ''\n","    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n","               2: dict_char_to_int, 3: dict_char_to_int}\n","    for j in [0, 1, 2, 3, 4, 5, 6]:\n","        if text[j] in mapping[j].keys():\n","            license_plate_ += mapping[j][text[j]]\n","        else:\n","            license_plate_ += text[j]\n","\n","    return license_plate_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ewdkg-sSvYh_"},"outputs":[],"source":["def read_license_plate(license_plate_crop):\n","    detections = reader.readtext(license_plate_crop)\n","\n","    for detection in detections:\n","        bbox, text, score = detection\n","\n","        text = text.upper().replace(' ', '')\n","\n","        # verify that text is conform to a standard license plate\n","        if license_complies_format(text):\n","            # bring text into the default license plate format\n","            return format_license(text), score\n","\n","    return None, None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQbKsKhDvYh_"},"outputs":[],"source":["results = {}\n","\n","# read video by index\n","video = cv.VideoCapture(videos[1])\n","\n","ret = True\n","frame_number = -1\n","vehicles = [2,3,5]\n","\n","# read the entire video\n","while ret:\n","    ret, frame = video.read()\n","    frame_number += 1\n","    if ret:\n","        results[frame_number] = {}\n","\n","        # vehicle detector\n","        detections = coco_model.track(frame, persist=True)[0]\n","        for detection in detections.boxes.data.tolist():\n","            x1, y1, x2, y2, track_id, score, class_id = detection\n","            if int(class_id) in vehicles and score > 0.5:\n","                vehicle_bounding_boxes = []\n","                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n","                for bbox in vehicle_bounding_boxes:\n","                    print(bbox)\n","                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n","\n","                    # license plate detector for region of interest\n","                    license_plates = np_model(roi)[0]\n","                    # process license plate\n","                    for license_plate in license_plates.boxes.data.tolist():\n","                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n","                        # crop plate from region of interest\n","                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n","                        # de-colorize\n","                        plate_gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n","                        # posterize\n","                        _, plate_treshold = cv.threshold(plate_gray, 64, 255, cv.THRESH_BINARY_INV)\n","\n","                        # OCR\n","                        np_text, np_score = read_license_plate(plate_treshold)\n","                        # if plate could be read write results\n","                        if np_text is not None:\n","                            results[frame_number][track_id] = {\n","                                'car': {\n","                                    'bbox': [x1, y1, x2, y2],\n","                                    'bbox_score': score\n","                                },\n","                                'license_plate': {\n","                                    'bbox': [plate_x1, plate_y1, plate_x2, plate_y2],\n","                                    'bbox_score': plate_score,\n","                                    'number': np_text,\n","                                    'text_score': np_score\n","                                }\n","                            }\n","\n","write_csv(results, './results.csv')\n","video.release()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAcoFM2VvYh_"},"outputs":[],"source":["results = pd.read_csv('./results.csv')\n","\n","# show results for tracking ID `1` - sort by OCR prediction confidence\n","results[results['track_id'] == 1.].sort_values(by='license_text_score', ascending=False)"]},{"cell_type":"markdown","metadata":{"id":"_ExUcYcivYh_"},"source":["# STEP 6 Visualize the Results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h5HBybWvvYiA"},"outputs":[],"source":["def draw_border(img, top_left, bottom_right, color=(0, 255, 0), thickness=6, line_length_x=200, line_length_y=200):\n","    x1, y1 = top_left\n","    x2, y2 = bottom_right\n","\n","    cv.line(img, (x1, y1), (x1, y1 + line_length_y), color, thickness)  #-- top-left\n","    cv.line(img, (x1, y1), (x1 + line_length_x, y1), color, thickness)\n","\n","    cv.line(img, (x1, y2), (x1, y2 - line_length_y), color, thickness)  #-- bottom-left\n","    cv.line(img, (x1, y2), (x1 + line_length_x, y2), color, thickness)\n","\n","    cv.line(img, (x2, y1), (x2 - line_length_x, y1), color, thickness)  #-- top-right\n","    cv.line(img, (x2, y1), (x2, y1 + line_length_y), color, thickness)\n","\n","    cv.line(img, (x2, y2), (x2, y2 - line_length_y), color, thickness)  #-- bottom-right\n","    cv.line(img, (x2, y2), (x2 - line_length_x, y2), color, thickness)\n","\n","    return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jPYUlZypvYiA"},"outputs":[],"source":["# read video by index\n","video = cv.VideoCapture(videos[1])\n","\n","# get video dims\n","frame_width = int(video.get(3))\n","frame_height = int(video.get(4))\n","size = (frame_width, frame_height)\n","\n","# Define the codec and create VideoWriter object\n","fourcc = cv.VideoWriter_fourcc(*'DIVX')\n","out = cv.VideoWriter('./outputs/processed.avi', fourcc, 20.0, size)\n","\n","# reset video before you re-run cell below\n","frame_number = -1\n","video.set(cv.CAP_PROP_POS_FRAMES, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VVGldR9WvYiA"},"outputs":[],"source":["ret = True\n","\n","while ret:\n","    ret, frame = video.read()\n","    frame_number += 1\n","    if ret:\n","        df_ = results[results['frame_number'] == frame_number]\n","        for index in range(len(df_)):\n","            # draw car\n","            vhcl_x1, vhcl_y1, vhcl_x2, vhcl_y2 = ast.literal_eval(df_.iloc[index]['car_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n","\n","            draw_border(\n","                frame, (int(vhcl_x1), int(vhcl_y1)),\n","                (int(vhcl_x2), int(vhcl_y2)), (0, 255, 0),\n","                12, line_length_x=200, line_length_y=200)\n","\n","            # draw license plate\n","            plate_x1, plate_y1, plate_x2, plate_y2 = ast.literal_eval(df_.iloc[index]['license_plate_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n","\n","            # region of interest\n","            roi = frame[int(vhcl_y1):int(vhcl_y2), int(vhcl_x1):int(vhcl_x2)]\n","            cv.rectangle(roi, (int(plate_x1), int(plate_y1)), (int(plate_x2), int(plate_y2)), (0, 0, 255), 6)\n","\n","            # write detected number\n","            (text_width, text_height), _ = cv.getTextSize(\n","                df_.iloc[index]['license_plate_number'],\n","                cv.FONT_HERSHEY_SIMPLEX,\n","                2,\n","                6)\n","\n","            cv.putText(\n","                frame,\n","                df_.iloc[index]['license_plate_number'],\n","                (int((vhcl_x2 + vhcl_x1 - text_width)/2), int(vhcl_y1 - text_height)),\n","                cv.FONT_HERSHEY_SIMPLEX,\n","                2,\n","                (0, 255, 0),\n","                6\n","            )\n","\n","        out.write(frame)\n","        frame = cv.resize(frame, (1280, 720))\n","\n","out.release()\n","video.release()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"classification","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
